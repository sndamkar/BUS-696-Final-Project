---
title: "Final Project BUS 696: Hotel Booking Demand"
author: "Brian Chun, Savin Damkar, Hasnu Kwatra"
date: "12/16/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(tidyverse)
library(rsample)
library(glmnet)
library(glmnetUtils)
library(coefplot)
library(plotROC)
library(yardstick)
library(partykit)
library(rpart)
library(rpart.plot)
library(randomForest)
library(randomForestExplainer)
library(lime)
library(data.table)
library(ISLR)

options(scipen = 50)
set.seed(23)

# Read data using relative path
hotels <- read_csv(here("datasets", "hotel_bookings.csv"))

# Overview of dataset dimensions and columns
dim(hotels)
colnames(hotels)

# Remove rows with missing values
hotels <- hotels %>% 
  drop_na()

glimpse(hotels)

# Convert relevant columns to factors and lump rare levels
hotels_clean <- hotels %>%
  mutate(across(c(hotel, country, is_canceled, is_repeated_guest,
                  market_segment, reserved_room_type, assigned_room_type,
                  deposit_type, meal, arrival_date_month, customer_type),
                as_factor)) %>%
  mutate(
    country = fct_lump(country, n = 4),
    market_segment = fct_lump(market_segment, n = 3),
    reserved_room_type = fct_lump(reserved_room_type, n = 3),
    assigned_room_type = fct_lump(assigned_room_type, n = 3),
    customer_type = fct_lump(customer_type, n = 3),
    arrival_date_month = fct_lump(arrival_date_month, n = 3)
  ) %>%
  select(is_canceled, hotel, lead_time, country,
         market_segment, is_repeated_guest, previous_cancellations,
         reserved_room_type, assigned_room_type, meal,
         booking_changes, deposit_type, customer_type, total_of_special_requests,
         adr, arrival_date_month, adults, children, babies, required_car_parking_spaces)

# Label the cancellation factor levels
levels(hotels_clean$is_canceled) <- c("Not Cancelled", "Cancelled")

# Split data into train (80%) and test (20%)
hotel_split <- initial_split(hotels_clean, prop = 0.8)
train <- training(hotel_split)
test <- testing(hotel_split)

glimpse(train)

# Common plot theme
common_theme <- theme_minimal() + theme(text = element_text(size = 14))

# Deposit Type distribution by cancellation status
ggplot(train, aes(x = deposit_type)) +
  geom_bar(fill = "black") +
  facet_wrap(~ is_canceled) +
  labs(title = "Deposit Type Distribution by Cancellation Status", x = "Deposit Type", y = "Count") +
  common_theme

# Country distribution
ggplot(train, aes(x = country)) +
  geom_bar(fill = "black") +
  labs(title = "Country Distribution", x = "Country", y = "Count") +
  common_theme

# Helper function for fitting logistic models and printing summary
fit_logistic <- function(formula, data) {
  model <- glm(formula, data = data, family = binomial)
  print(summary(model))
  return(model)
}

# Full logistic model with selected features
logit_hotel <- fit_logistic(
  is_canceled ~ hotel + lead_time + country + market_segment + 
    is_repeated_guest + previous_cancellations + reserved_room_type + 
    booking_changes + deposit_type + total_of_special_requests,
  train)

# Simpler logistic models to interpret coefficients
logit_hotel1 <- fit_logistic(is_canceled ~ hotel + lead_time + market_segment + total_of_special_requests, train)

logit_hotel2 <- fit_logistic(is_canceled ~ hotel + lead_time + booking_changes + total_of_special_requests, train)

logit_hotel3 <- fit_logistic(is_canceled ~ hotel + lead_time + booking_changes + deposit_type + previous_cancellations, train)

logit_hotel4 <- fit_logistic(is_canceled ~ hotel + lead_time + market_segment + previous_cancellations, train)

# Convert factors to numeric model matrix for glmnet
x_train <- model.matrix(is_canceled ~ hotel + lead_time + country + market_segment + is_repeated_guest + 
                          previous_cancellations + reserved_room_type + booking_changes + deposit_type + total_of_special_requests, 
                        data = train)[,-1]  # remove intercept

y_train <- as.numeric(train$is_canceled) - 1  # binary response 0/1

# Ridge Regression (alpha = 0)
ridge_mod <- cv.glmnet(x_train, y_train, family = "binomial", alpha = 0)
plot(ridge_mod)

# Lasso Regression (alpha = 1)
lasso_mod <- cv.glmnet(x_train, y_train, family = "binomial", alpha = 1)
plot(lasso_mod)

# Elastic Net (alpha tuning)
enet_mod <- cva.glmnet(x_train, y_train, family = "binomial", alpha = seq(0,1, by = 0.1))
minlossplot(enet_mod, cv.type = "min")

# Extract best alpha
get_alpha <- function(fit) {
  alpha <- fit$alpha
  error <- sapply(fit$modlist, function(mod) min(mod$cvm))
  alpha[which.min(error)]
}

best_alpha <- get_alpha(enet_mod)
print(paste("Best alpha:", best_alpha))

coefs <- data.table(
  varnames = rownames(coef(ridge_mod, s = "lambda.min")),
  ridge_lambda_min = as.matrix(coef(ridge_mod, s = "lambda.min")),
  lasso_lambda_min = as.matrix(coef(lasso_mod, s = "lambda.min"))
)
print(coefs)

# Predict probabilities on train and test sets
train_pred <- predict(logit_hotel, newdata = train, type = "response")
test_pred <- predict(logit_hotel, newdata = test, type = "response")

# Prepare dataframes for ROC curves
train_results <- tibble(truth = train$is_canceled, estimate = train_pred)
test_results <- tibble(truth = test$is_canceled, estimate = test_pred)

# ROC curves
train_roc <- roc_curve(train_results, truth = truth, estimate = estimate)
test_roc <- roc_curve(test_results, truth = truth, estimate = estimate)

# Plot ROC curves
ggplot(train_roc) + 
  geom_path(aes(x = 1 - specificity, y = sensitivity), color = "blue") +
  ggtitle("Train ROC Curve") +
  common_theme

ggplot(test_roc) + 
  geom_path(aes(x = 1 - specificity, y = sensitivity), color = "red") +
  ggtitle("Test ROC Curve") +
  common_theme

# AUC values
train_auc <- roc_auc(train_results, truth = truth, estimate = estimate)
test_auc <- roc_auc(test_results, truth = truth, estimate = estimate)

print(train_auc)
print(test_auc)

# Build classification results data frame
results_logit <- test_results %>%
  mutate(
    predicted = factor(if_else(estimate > 0.5, "Cancelled", "Not Cancelled"),
                       levels = c("Not Cancelled", "Cancelled")),
    truth = factor(truth, levels = c("Not Cancelled", "Cancelled"))
  )

# Confusion matrix
cm <- conf_mat(results_logit, truth = truth, estimate = predicted)
print(cm)
summary(cm)

# Print metrics for clarity
metrics <- metrics(results_logit, truth = truth, estimate = predicted)
print(metrics)

mtry_vals <- 1:10

oob_err <- sapply(mtry_vals, function(m) {
  rf <- randomForest(is_canceled ~ hotel + lead_time + country + market_segment + is_repeated_guest +
                       previous_cancellations + reserved_room_type + booking_changes + deposit_type + total_of_special_requests,
                     data = train,
                     mtry = m,
                     ntree = 200,
                     na.action = na.omit,
                     localImp = TRUE)
  rf$err.rate[200, "OOB"]
})

tibble(mtry = mtry_vals, oob_err = oob_err) %>%
  ggplot(aes(mtry, oob_err)) +
  geom_point() +
  labs(title = "Random Forest OOB Error vs mtry") +
  common_theme

optimal_mtry <- mtry_vals[which.min(oob_err)]
cat("Optimal mtry:", optimal_mtry, "\n")

rf_fit <- randomForest(is_canceled ~ hotel + lead_time + country + market_segment + is_repeated_guest +
                         previous_cancellations + reserved_room_type + booking_changes + deposit_type + total_of_special_requests,
                       data = train,
                       mtry = optimal_mtry,
                       ntree = 200,
                       na.action = na.omit,
                       localImp = TRUE)

# Variable importance plots
varImpPlot(rf_fit)

# Additional Random Forest explanations
plot_min_depth_distribution(rf_fit)

plot_multi_way_importance(rf_fit, size_measure = "no_of_nodes")

explain_forest(rf_fit, interactions = TRUE, data = train)

# Tune mtry using all features
all_mtry_vals <- 1:ncol(select(hotels_clean, -is_canceled))

all_oob_err <- sapply(all_mtry_vals, function(m) {
  rf <- randomForest(is_canceled ~ ., data = hotels_clean,
                     mtry = m,
                     ntree = 200,
                     na.action = na.omit,
                     localImp = TRUE)
  rf$err.rate[200, "OOB"]
})

tibble(mtry = all_mtry_vals, oob_err = all_oob_err) %>%
  ggplot(aes(mtry, oob_err)) +
  geom_point() +
  labs(title = "Random Forest OOB Error vs mtry (All Variables)") +
  common_theme

# Fit final RF with best mtry
best_all_mtry <- all_mtry_vals[which.min(all_oob_err)]
cat("Best mtry with all variables:", best_all_mtry, "\n")

rf_fit_all <- randomForest(is_canceled ~ ., data = hotels_clean,
                           mtry = best_all_mtry,
                           ntree = 200,
                           na.action = na.omit,
                           localImp = TRUE)

# Variable importance plot
varImpPlot(rf_fit_all)

# --- LIME Explanation Section ---

library(lime)

# Prepare explainer with training features (exclude outcome)
train_features <- train %>% select(-is_canceled)

# Create explainer object for your random forest model
explainer_rf <- lime(train_features, rf_fit3)  # rf_fit3 is your final RF model

# Select a few test observations to explain (e.g., first 3 rows)
test_features <- test %>% select(-is_canceled)
test_sample <- test_features[1:3, ]

# Generate explanations for these observations
explanations <- explain(test_sample, explainer_rf, n_features = 5)

# Visualize feature contributions for each observation
plot_features(explanations) +
  ggtitle("LIME Feature Contributions for Selected Test Bookings")

```
